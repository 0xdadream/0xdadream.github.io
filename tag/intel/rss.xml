<?xml version="1.0"?>
<rss version="2.0">
    <channel>
        <title>逐梦 • Posts by &#34;intel&#34; tag</title>
        <link>https://0xdadream.github.io</link>
        <description>Welcome to my blog</description>
        <language>zh-CN</language>
        <pubDate>Thu, 20 Feb 2025 12:25:00 +0800</pubDate>
        <lastBuildDate>Thu, 20 Feb 2025 12:25:00 +0800</lastBuildDate>
        <category>tip</category>
        <category>intel</category>
        <category>cloudflare</category>
        <category>tips</category>
        <category>安装</category>
        <category>re</category>
        <category>工具</category>
        <category>Java</category>
        <category>教程</category>
        <category>linux</category>
        <category>环境</category>
        <category>conda</category>
        <category>bug</category>
        <category>windows</category>
        <category>web</category>
        <category>wp</category>
        <category>BUUCTF</category>
        <category>攻防世界</category>
        <category>server</category>
        <category>wall</category>
        <category>comfyui</category>
        <category>powershell</category>
        <category>tools</category>
        <category>sql</category>
        <category>代码审计</category>
        <category>漏洞复现</category>
        <category>emby</category>
        <category>python</category>
        <category>git</category>
        <category>google</category>
        <category>java</category>
        <category>学习</category>
        <category>命令</category>
        <category>远程</category>
        <category>php</category>
        <category>文件上传</category>
        <category>命令行</category>
        <category>下载</category>
        <category>区块链</category>
        <category>汇编</category>
        <category>密码学</category>
        <category>i春秋</category>
        <category>证书</category>
        <item>
            <guid isPermalink="true">https://0xdadream.github.io/2025/02/20/arc-zai-comfyui-bao-cuo/</guid>
            <title>Arc在comfyui报错</title>
            <link>https://0xdadream.github.io/2025/02/20/arc-zai-comfyui-bao-cuo/</link>
            <category>intel</category>
            <pubDate>Thu, 20 Feb 2025 12:25:00 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;Arc在comfyui报错&#34;&gt;&lt;a href=&#34;#Arc在comfyui报错&#34; class=&#34;headerlink&#34; title=&#34;Arc在comfyui报错&#34;&gt;&lt;/a&gt;Arc在comfyui报错&lt;/h1&gt;&lt;h2 id=&#34;报错&#34;&gt;&lt;a href=&#34;#报错&#34; class=&#34;headerlink&#34; title=&#34;报错&#34;&gt;&lt;/a&gt;报错&lt;/h2&gt;&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;Current platform can NOT allocate memory block with size larger than 4GB&lt;span class=&#34;token operator&#34;&gt;!&lt;/span&gt; Tried to allocate &lt;span class=&#34;token number&#34;&gt;8.00&lt;/span&gt; GiB &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;GPU &lt;span class=&#34;token number&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;15.56&lt;/span&gt; GiB total capacity&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;2.08&lt;/span&gt; GiB already allocated&lt;span class=&#34;token punctuation&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;2.12&lt;/span&gt; GiB reserved &lt;span class=&#34;token keyword&#34;&gt;in&lt;/span&gt; total by PyTorch&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;目前的解决办法都不太行，我的做法是回到&lt;code&gt;IPEX-2.1&lt;/code&gt;版本&lt;/p&gt;
&lt;h2 id=&#34;参考链接&#34;&gt;&lt;a href=&#34;#参考链接&#34; class=&#34;headerlink&#34; title=&#34;参考链接&#34;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/intel/intel-extension-for-pytorch/issues/325#issuecomment-2604803076&#34;&gt;Arrays larger than 4 GB crashes · Issue #325 · intel/intel-extension-for-pytorch&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://0xdadream.github.io/2025/02/18/arca770-shi-yong-comfyui-jiao-cheng/</guid>
            <title>ArcA770使用comfyui教程</title>
            <link>https://0xdadream.github.io/2025/02/18/arca770-shi-yong-comfyui-jiao-cheng/</link>
            <category>intel</category>
            <pubDate>Tue, 18 Feb 2025 18:11:00 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;ArcA770使用comfyui教程&#34;&gt;&lt;a href=&#34;#ArcA770使用comfyui教程&#34; class=&#34;headerlink&#34; title=&#34;ArcA770使用comfyui教程&#34;&gt;&lt;/a&gt;ArcA770使用comfyui教程&lt;/h1&gt;&lt;h3 id=&#34;1-前置配置&#34;&gt;&lt;a href=&#34;#1-前置配置&#34; class=&#34;headerlink&#34; title=&#34;1. 前置配置&#34;&gt;&lt;/a&gt;&lt;strong&gt;1. 前置配置&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;conda&lt;/li&gt;
&lt;li&gt;更新驱动&lt;/li&gt;
&lt;li&gt;安装&lt;strong&gt;Visual Studio Build Tools&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;安装oneAPI&lt;/li&gt;
&lt;li&gt;安装IPEX&lt;/li&gt;
&lt;li&gt;具体看链接&lt;a href=&#34;https://0xdadream.github.io/2025/02/18/intel-xian-qia-pao-ai-pei-zhi-jiao-cheng/&#34;&gt;Intel显卡运行AI配置教程 | 逐梦&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;2-配置Python&#34;&gt;&lt;a href=&#34;#2-配置Python&#34; class=&#34;headerlink&#34; title=&#34;2. 配置Python&#34;&gt;&lt;/a&gt;&lt;strong&gt;2. 配置Python&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Python环境&lt;/strong&gt;：&lt;br&gt;建议使用&lt;strong&gt;Python 3.10或更高版本&lt;/strong&gt;，并通过虚拟环境（如&lt;code&gt;venv&lt;/code&gt;或&lt;code&gt;conda&lt;/code&gt;）隔离依赖。&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create &lt;span class=&#34;token parameter variable&#34;&gt;-n&lt;/span&gt; comfyui &lt;span class=&#34;token assign-left variable&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;3.11&lt;/span&gt;  这里comfyui就是安装IPEX的环境
conda activate comfyui&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;3-安装ComfyUI及依赖库&#34;&gt;&lt;a href=&#34;#3-安装ComfyUI及依赖库&#34; class=&#34;headerlink&#34; title=&#34;3. 安装ComfyUI及依赖库&#34;&gt;&lt;/a&gt;&lt;strong&gt;3. 安装ComfyUI及依赖库&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;克隆ComfyUI仓库&lt;/strong&gt;：&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;&lt;span class=&#34;token builtin class-name&#34;&gt;cd&lt;/span&gt; xxxx &lt;span class=&#34;token comment&#34;&gt;#工作目录&lt;/span&gt;
&lt;span class=&#34;token function&#34;&gt;git&lt;/span&gt; clone https://github.com/comfyanonymous/ComfyUI.git
&lt;span class=&#34;token builtin class-name&#34;&gt;cd&lt;/span&gt; ComfyUI
pip &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;token parameter variable&#34;&gt;-r&lt;/span&gt; requirements.txt &lt;span class=&#34;token comment&#34;&gt;# 安装依赖&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;4-验证显卡识别与性能调优&#34;&gt;&lt;a href=&#34;#4-验证显卡识别与性能调优&#34; class=&#34;headerlink&#34; title=&#34;4. 验证显卡识别与性能调优&#34;&gt;&lt;/a&gt;&lt;strong&gt;4. 验证显卡识别与性能调优&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;显存与算力优化&lt;/strong&gt;：&lt;ul&gt;
&lt;li&gt;启用Intel的&lt;strong&gt;XMX引擎&lt;/strong&gt;（AI加速单元）和&lt;strong&gt;XeSS技术&lt;/strong&gt;（超分辨率），可通过设置环境变量优化显存分配410。&lt;/li&gt;
&lt;li&gt;调整ComfyUI配置文件，指定使用&lt;code&gt;XPU&lt;/code&gt;（Intel GPU）而非默认的CUDA。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;5-启动comfyui&#34;&gt;&lt;a href=&#34;#5-启动comfyui&#34; class=&#34;headerlink&#34; title=&#34;5.启动comfyui&#34;&gt;&lt;/a&gt;&lt;strong&gt;5.启动comfyui&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;接着上面的目录执行&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;python main.py --use-pytorch-cross-attention &lt;span class=&#34;token parameter variable&#34;&gt;--highvram&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;快捷脚本&#34;&gt;&lt;a href=&#34;#快捷脚本&#34; class=&#34;headerlink&#34; title=&#34;快捷脚本&#34;&gt;&lt;/a&gt;快捷脚本&lt;/h4&gt;&lt;h5 id=&#34;cmd&#34;&gt;&lt;a href=&#34;#cmd&#34; class=&#34;headerlink&#34; title=&#34;cmd&#34;&gt;&lt;/a&gt;cmd&lt;/h5&gt;&lt;pre class=&#34;line-numbers language-bat&#34; data-language=&#34;bat&#34;&gt;&lt;code class=&#34;language-bat&#34;&gt;call &#34;E:\conda\Scripts\activate.bat&#34; deepl  
call &#34;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&#34;
python main.py --use-pytorch-cross-attention --highvram&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;保存为&lt;code&gt;.bat&lt;/code&gt;文件&lt;/p&gt;
&lt;p&gt;powershell&lt;/p&gt;
&lt;p&gt;没搞出来&lt;/p&gt;
 ]]></description>
        </item>
        <item>
            <guid isPermalink="true">https://0xdadream.github.io/2025/02/18/intel-xian-qia-pao-ai-pei-zhi-jiao-cheng/</guid>
            <title>Intel显卡运行AI配置教程</title>
            <link>https://0xdadream.github.io/2025/02/18/intel-xian-qia-pao-ai-pei-zhi-jiao-cheng/</link>
            <category>intel</category>
            <pubDate>Tue, 18 Feb 2025 16:11:00 +0800</pubDate>
            <description><![CDATA[ &lt;h1 id=&#34;Intel显卡运行AI配置教程&#34;&gt;&lt;a href=&#34;#Intel显卡运行AI配置教程&#34; class=&#34;headerlink&#34; title=&#34;Intel显卡运行AI配置教程&#34;&gt;&lt;/a&gt;&lt;strong&gt;Intel显卡运行AI配置教程&lt;/strong&gt;&lt;/h1&gt;&lt;h2 id=&#34;最新&#34;&gt;&lt;a href=&#34;#最新&#34; class=&#34;headerlink&#34; title=&#34;最新&#34;&gt;&lt;/a&gt;最新&lt;/h2&gt;&lt;p&gt;最近pytorch已经支持Arc显卡了，不需要再安装oneAPI和IPEX，当然以前的版本仍需要（2.5及以前），但是我本地本来是安装过这些组件的，我也不知道不安装会不会报错，可以参考官方文档&lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpu/2-6.html&#34;&gt;PyTorch Prerequisites for Intel® GPUs&lt;/a&gt;，pytorch开发者确实说过免去了那些复杂的操作，可以开箱即用&lt;/p&gt;
&lt;h3 id=&#34;安装&#34;&gt;&lt;a href=&#34;#安装&#34; class=&#34;headerlink&#34; title=&#34;安装&#34;&gt;&lt;/a&gt;安装&lt;/h3&gt;&lt;p&gt;直接在conda环境中执行即可&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate deepl
pip3 &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;token parameter variable&#34;&gt;--pre&lt;/span&gt; torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;输出true就是成功了&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-python&#34; data-language=&#34;python&#34;&gt;&lt;code class=&#34;language-python&#34;&gt;&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; torch
torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;xpu&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;is_available&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;  &lt;span class=&#34;token comment&#34;&gt;# torch.xpu is the API for Intel GPU support&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;训练测试代码&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-python&#34; data-language=&#34;python&#34;&gt;&lt;code class=&#34;language-python&#34;&gt;&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; torch
&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; torchvision

LR &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0.001&lt;/span&gt;
DOWNLOAD &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token boolean&#34;&gt;True&lt;/span&gt;
DATA &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token string&#34;&gt;&#34;datasets/cifar10/&#34;&lt;/span&gt;

transform &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; torchvision&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;transforms&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Compose&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;token punctuation&#34;&gt;[&lt;/span&gt;
        torchvision&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;transforms&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Resize&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;224&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;224&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
        torchvision&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;transforms&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;ToTensor&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
        torchvision&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;transforms&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;Normalize&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0.5&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;token punctuation&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
train_dataset &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; torchvision&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;datasets&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;CIFAR10&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;
    root&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;DATA&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
    train&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;token boolean&#34;&gt;True&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
    transform&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;transform&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
    download&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;DOWNLOAD&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
train_loader &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;utils&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;data&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;DataLoader&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;dataset&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;train_dataset&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; batch_size&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;128&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
train_len &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;token builtin&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;train_loader&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;

model &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; torchvision&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;models&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;resnet50&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
criterion &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;nn&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;CrossEntropyLoss&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
optimizer &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;optim&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;SGD&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;model&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;parameters&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; lr&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;LR&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; momentum&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;0.9&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
model&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;train&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
model &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; model&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;to&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;xpu&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
criterion &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; criterion&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;to&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;xpu&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string-interpolation&#34;&gt;&lt;span class=&#34;token string&#34;&gt;f&#34;Initiating training&#34;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;token keyword&#34;&gt;for&lt;/span&gt; batch_idx&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;data&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; target&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token keyword&#34;&gt;in&lt;/span&gt; &lt;span class=&#34;token builtin&#34;&gt;enumerate&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;train_loader&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;
    data &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; data&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;to&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;xpu&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    target &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; target&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;to&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;xpu&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    optimizer&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;zero_grad&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    output &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; model&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;data&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    loss &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; criterion&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;output&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt; target&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    loss&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;backward&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    optimizer&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;step&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;token keyword&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;batch_idx &lt;span class=&#34;token operator&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;%&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;token number&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;
         iteration_loss &lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt; loss&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;item&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
         &lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string-interpolation&#34;&gt;&lt;span class=&#34;token string&#34;&gt;f&#34;Iteration [&lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;batch_idx&lt;span class=&#34;token operator&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;train_len&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;], Loss: &lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;iteration_loss&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;token format-spec&#34;&gt;.4f&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;
torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;save&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;
    &lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;token string&#34;&gt;&#34;model_state_dict&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt; model&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;state_dict&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;token string&#34;&gt;&#34;optimizer_state_dict&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;:&lt;/span&gt; optimizer&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;state_dict&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;token string&#34;&gt;&#34;checkpoint.pth&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;

&lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;Execution finished&#34;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;适用硬件&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intel Arc系列显卡（如A770 16G）驱动为6559&lt;/li&gt;
&lt;li&gt;win11&lt;/li&gt;
&lt;li&gt;oneAPI==2025.0.1&lt;/li&gt;
&lt;li&gt;torch==2.3.110&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-安装Miniconda并配置Python虚拟环境&#34;&gt;&lt;a href=&#34;#1-安装Miniconda并配置Python虚拟环境&#34; class=&#34;headerlink&#34; title=&#34;1. 安装Miniconda并配置Python虚拟环境&#34;&gt;&lt;/a&gt;&lt;strong&gt;1. 安装Miniconda并配置Python虚拟环境&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;可以参考这个&lt;a href=&#34;https://0xdadream.github.io/2024/08/12/conda-an-zhuang-ji-shi-yong/&#34;&gt;conda安装及使用 | 逐梦&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;步骤说明&#34;&gt;&lt;a href=&#34;#步骤说明&#34; class=&#34;headerlink&#34; title=&#34;步骤说明&#34;&gt;&lt;/a&gt;&lt;strong&gt;步骤说明&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;下载Miniconda&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;访问 &lt;a href=&#34;https://docs.conda.io/en/latest/miniconda.html&#34;&gt;Miniconda官网&lt;/a&gt;，选择对应操作系统的安装包（建议Python 3.11版本）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;安装Miniconda&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows：双击安装包，按提示操作，勾选“Add to PATH”选项。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Linux/macOS：&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;&lt;span class=&#34;token function&#34;&gt;bash&lt;/span&gt; Miniconda3-latest-Linux-x86_64.sh  &lt;span class=&#34;token comment&#34;&gt;# 根据文件名调整  &lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;创建Python 3.11虚拟环境&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;conda create &lt;span class=&#34;token parameter variable&#34;&gt;-n&lt;/span&gt; intel-ai &lt;span class=&#34;token assign-left variable&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;3.11&lt;/span&gt;  
conda activate intel-ai  &lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;2-更新Intel显卡驱动&#34;&gt;&lt;a href=&#34;#2-更新Intel显卡驱动&#34; class=&#34;headerlink&#34; title=&#34;2. 更新Intel显卡驱动&#34;&gt;&lt;/a&gt;&lt;strong&gt;2. 更新Intel显卡驱动&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&#34;关键操作&#34;&gt;&lt;a href=&#34;#关键操作&#34; class=&#34;headerlink&#34; title=&#34;关键操作&#34;&gt;&lt;/a&gt;&lt;strong&gt;关键操作&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;下载最新驱动&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;访问 &lt;a href=&#34;https://www.intel.cn/content/www/cn/zh/download-center/home.html&#34;&gt;Intel驱动下载页&lt;/a&gt;，选择Arc系列显卡的最新驱动（如&lt;strong&gt;32.0.101.6559&lt;/strong&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;安装驱动&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows：运行安装程序，按提示完成安装。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Linux：使用包管理器（如Ubuntu/Debian）：&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;&lt;span class=&#34;token function&#34;&gt;sudo&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;apt&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; intel-opencl-icd intel-level-zero-gpu level-zero  &lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;验证驱动状态&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows：按 &lt;code&gt;Win + X&lt;/code&gt; &amp;gt; 设备管理器 &amp;gt; 显示适配器，确认显卡型号正确。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Linux：&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;lspci &lt;span class=&#34;token operator&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;token function&#34;&gt;grep&lt;/span&gt; &lt;span class=&#34;token parameter variable&#34;&gt;-i&lt;/span&gt; intel  &lt;span class=&#34;token comment&#34;&gt;# 确认显卡识别  &lt;/span&gt;
clinfo  &lt;span class=&#34;token comment&#34;&gt;# 检查OpenCL支持  &lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;3-安装Visual-Studio-Build-Tools（仅Windows）&#34;&gt;&lt;a href=&#34;#3-安装Visual-Studio-Build-Tools（仅Windows）&#34; class=&#34;headerlink&#34; title=&#34;3. 安装Visual Studio Build Tools（仅Windows）&#34;&gt;&lt;/a&gt;&lt;strong&gt;3. 安装Visual Studio Build Tools（仅Windows）&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&#34;操作步骤&#34;&gt;&lt;a href=&#34;#操作步骤&#34; class=&#34;headerlink&#34; title=&#34;操作步骤&#34;&gt;&lt;/a&gt;&lt;strong&gt;操作步骤&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;下载Visual Studio 2022&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;访问 &lt;a href=&#34;https://visualstudio.microsoft.com/&#34;&gt;Visual Studio官网&lt;/a&gt;，下载社区版。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安装C++桌面开发组件&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;在安装界面勾选：&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;使用C++的桌面开发&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Windows 10/11 SDK&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C++ CMake工具&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;默认也行&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;验证安装&lt;/strong&gt;&lt;ul&gt;
&lt;li&gt;打开命令提示符，运行 &lt;code&gt;cl&lt;/code&gt; 命令，确认返回编译器版本信息。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;4-安装Intel-oneAPI工具包&#34;&gt;&lt;a href=&#34;#4-安装Intel-oneAPI工具包&#34; class=&#34;headerlink&#34; title=&#34;4. 安装Intel oneAPI工具包&#34;&gt;&lt;/a&gt;&lt;strong&gt;4. 安装Intel oneAPI工具包&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&#34;步骤说明-1&#34;&gt;&lt;a href=&#34;#步骤说明-1&#34; class=&#34;headerlink&#34; title=&#34;步骤说明&#34;&gt;&lt;/a&gt;&lt;strong&gt;步骤说明&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;下载oneAPI Base Toolkit&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;访问 &lt;a href=&#34;https://www.intel.cn/content/www/cn/zh/developer/tools/oneapi/toolkits.html&#34;&gt;oneAPI官网&lt;/a&gt;，选择Base Toolkit-&amp;gt;windows-&amp;gt;offline installer，然后点击右边往下一点Continue as a Guest (download starts immediately) →下载&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;安装oneAPI&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows：运行安装程序，默认勾选所有组件，一直点就行了。&lt;/li&gt;
&lt;li&gt;Linux：使用包管理器或脚本安装。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;激活oneAPI环境变量&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Windows：&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;call &lt;span class=&#34;token string&#34;&gt;&#34;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&#34;&lt;/span&gt;   &lt;span class=&#34;token comment&#34;&gt;# cmd使用&lt;/span&gt;
cmd.exe &lt;span class=&#34;token string&#34;&gt;&#34;/K&#34;&lt;/span&gt; &lt;span class=&#34;token string&#34;&gt;&#39;&#34;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&#34; &amp;amp;&amp;amp; powershell&#39;&lt;/span&gt; &lt;span class=&#34;token comment&#34;&gt;# powershell使用&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Linux：&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;&lt;span class=&#34;token builtin class-name&#34;&gt;source&lt;/span&gt; /opt/intel/oneapi/setvars.sh  &lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;5-安装Intel-Extension-for-PyTorch-IPEX&#34;&gt;&lt;a href=&#34;#5-安装Intel-Extension-for-PyTorch-IPEX&#34; class=&#34;headerlink&#34; title=&#34;5. 安装Intel Extension for PyTorch (IPEX)&#34;&gt;&lt;/a&gt;&lt;strong&gt;5. 安装Intel Extension for PyTorch (IPEX)&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&#34;操作命令&#34;&gt;&lt;a href=&#34;#操作命令&#34; class=&#34;headerlink&#34; title=&#34;操作命令&#34;&gt;&lt;/a&gt;&lt;strong&gt;操作命令&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;激活虚拟环境与oneAPI&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;powershell中执行&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;&lt;span class=&#34;token builtin class-name&#34;&gt;cd&lt;/span&gt; xxx &lt;span class=&#34;token comment&#34;&gt;#最好切换到工作目录&lt;/span&gt;
conda create &lt;span class=&#34;token parameter variable&#34;&gt;-n&lt;/span&gt; intel-ai &lt;span class=&#34;token assign-left variable&#34;&gt;python&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;3.11&lt;/span&gt;  &lt;span class=&#34;token comment&#34;&gt;# 前面创建过环境没有再次创建&lt;/span&gt;
conda activate intel-ai &lt;span class=&#34;token comment&#34;&gt;# 激活环境 &lt;/span&gt;
conda &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; libjepg-turbo &lt;span class=&#34;token comment&#34;&gt;#提前安装这两个库以免报错&lt;/span&gt;
conda &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; libpng 
cmd.exe &lt;span class=&#34;token string&#34;&gt;&#34;/K&#34;&lt;/span&gt; &lt;span class=&#34;token string&#34;&gt;&#39;&#34;C:\Program Files (x86)\Intel\oneAPI\setvars.bat&#34; &amp;amp;&amp;amp; powershell&#39;&lt;/span&gt;  &lt;span class=&#34;token comment&#34;&gt;# 根据操作系统执行上述对应的oneAPI激活命令&lt;/span&gt;
conda activate intel-ai &lt;span class=&#34;token comment&#34;&gt;# 再次激活环境&lt;/span&gt;
conda &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; pkg-config libuv &lt;span class=&#34;token comment&#34;&gt;# 安装一些依赖&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;安装PyTorch与IPEX&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;&lt;span class=&#34;token comment&#34;&gt;# 安装PyTorch CPU版本（IPEX会自动启用GPU支持）  &lt;/span&gt;
pip &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;token assign-left variable&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2.3&lt;/span&gt;.1.post0+cxx11.abi &lt;span class=&#34;token assign-left variable&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;0.18&lt;/span&gt;.1.post0+cxx11.abi &lt;span class=&#34;token assign-left variable&#34;&gt;torchaudio&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2.3&lt;/span&gt;.1.post0+cxx11.abi intel-extension-for-pytorch&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2.3&lt;/span&gt;.110.post0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/ &lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;pip &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;token assign-left variable&#34;&gt;torch&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2.5&lt;/span&gt;.1+cxx11.abi &lt;span class=&#34;token assign-left variable&#34;&gt;torchvision&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;0.20&lt;/span&gt;.1+cxx11.abi &lt;span class=&#34;token assign-left variable&#34;&gt;torchaudio&lt;/span&gt;&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2.5&lt;/span&gt;.1+cxx11.abi intel-extension-for-pytorch&lt;span class=&#34;token operator&#34;&gt;==&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;2.5&lt;/span&gt;.10+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/
&lt;span class=&#34;token comment&#34;&gt;# 最新版实测也能用&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;6-验证IPEX安装与显卡识别&#34;&gt;&lt;a href=&#34;#6-验证IPEX安装与显卡识别&#34; class=&#34;headerlink&#34; title=&#34;6. 验证IPEX安装与显卡识别&#34;&gt;&lt;/a&gt;&lt;strong&gt;6. 验证IPEX安装与显卡识别&lt;/strong&gt;&lt;/h2&gt;&lt;h3 id=&#34;验证步骤&#34;&gt;&lt;a href=&#34;#验证步骤&#34; class=&#34;headerlink&#34; title=&#34;验证步骤&#34;&gt;&lt;/a&gt;&lt;strong&gt;验证步骤&lt;/strong&gt;&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;运行Python脚本检查GPU支持&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-python&#34; data-language=&#34;python&#34;&gt;&lt;code class=&#34;language-python&#34;&gt;&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; torch  
&lt;span class=&#34;token keyword&#34;&gt;import&lt;/span&gt; intel_extension_for_pytorch &lt;span class=&#34;token keyword&#34;&gt;as&lt;/span&gt; ipex  

&lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string-interpolation&#34;&gt;&lt;span class=&#34;token string&#34;&gt;f&#34;PyTorch版本: &lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;__version__&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;  
&lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string-interpolation&#34;&gt;&lt;span class=&#34;token string&#34;&gt;f&#34;IPEX版本: &lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;ipex&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;__version__&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;  
&lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string-interpolation&#34;&gt;&lt;span class=&#34;token string&#34;&gt;f&#34;Intel GPU是否可用: &lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;xpu&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;is_available&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;  
&lt;span class=&#34;token keyword&#34;&gt;print&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token string-interpolation&#34;&gt;&lt;span class=&#34;token string&#34;&gt;f&#34;检测到的Intel GPU设备: &lt;/span&gt;&lt;span class=&#34;token interpolation&#34;&gt;&lt;span class=&#34;token punctuation&#34;&gt;{&lt;/span&gt;torch&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;xpu&lt;span class=&#34;token punctuation&#34;&gt;.&lt;/span&gt;get_device_name&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;token number&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token string&#34;&gt;&#34;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt;  &lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;python &lt;span class=&#34;token parameter variable&#34;&gt;-c&lt;/span&gt; &lt;span class=&#34;token string&#34;&gt;&#34;import torch; import intel_extension_for_pytorch as ipex; print(&#39;PyTorch版本:&#39;, torch.__version__); print(&#39;IPEX版本:&#39;, ipex.__version__); print(&#39;Intel GPU是否可用:&#39;, torch.xpu.is_available()); print(&#39;检测到的Intel GPU设备:&#39;, torch.xpu.get_device_name(0))&#34;&lt;/span&gt;
&lt;span class=&#34;token comment&#34;&gt;# 一键脚本&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;预期输出&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;PyTorch版本: &lt;span class=&#34;token number&#34;&gt;2.1&lt;/span&gt;.0  
IPEX版本: &lt;span class=&#34;token number&#34;&gt;2.1&lt;/span&gt;.0  
Intel GPU是否可用: True  
检测到的Intel GPU设备: Intel&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;R&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; Arc&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;TM&lt;span class=&#34;token punctuation&#34;&gt;)&lt;/span&gt; A770 Graphics  &lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;官方脚本&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;python &lt;span class=&#34;token parameter variable&#34;&gt;-c&lt;/span&gt; &lt;span class=&#34;token string&#34;&gt;&#34;import torch; import intel_extension_for_pytorch as ipex; print(torch.__version__); print(ipex.__version__); [print(f&#39;[{i}]: {torch.xpu.get_device_properties(i)}&#39;) for i in range(torch.xpu.device_count())];&#34;&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;至此已经安装成功了&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;hr&gt;
&lt;h2 id=&#34;7-常见问题解决&#34;&gt;&lt;a href=&#34;#7-常见问题解决&#34; class=&#34;headerlink&#34; title=&#34;7. 常见问题解决&#34;&gt;&lt;/a&gt;&lt;strong&gt;7. 常见问题解决&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;遇到问题大多数时候都是各种版本不匹配，例如&lt;code&gt;raise err OSError: [WinError 126] 找不到指定的模块。&lt;/code&gt;，尽量使用教程相同版本。&lt;/p&gt;
&lt;p&gt;报错信息&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;E:&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;conda&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;envs&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;deepll&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;Lib&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;site-packages&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;torchvision&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;io&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;image.py:14: UserWarning: Failed to load image Python extension: &lt;span class=&#34;token string&#34;&gt;&#39;Could not find module &#39;&lt;/span&gt;E:&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;conda&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;envs&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;deepll&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;Lib&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;site-packages&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;torchvision&lt;span class=&#34;token punctuation&#34;&gt;\&lt;/span&gt;image.pyd&lt;span class=&#34;token string&#34;&gt;&#39; (or one of its dependencies). Try using the full path with constructor syntax.&#39;&lt;/span&gt;If you don&#39;t plan on using image functionality from &lt;span class=&#34;token variable&#34;&gt;&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;torchvision.io&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;&lt;/span&gt;, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have &lt;span class=&#34;token variable&#34;&gt;&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;libjpeg&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;&lt;/span&gt; or &lt;span class=&#34;token variable&#34;&gt;&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;libpng&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;&lt;/span&gt; installed before building &lt;span class=&#34;token variable&#34;&gt;&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;torchvision&lt;span class=&#34;token variable&#34;&gt;`&lt;/span&gt;&lt;/span&gt; from source?
  warn&lt;span class=&#34;token punctuation&#34;&gt;(&lt;/span&gt;&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;解决方案&lt;/p&gt;
&lt;pre class=&#34;line-numbers language-bash&#34; data-language=&#34;bash&#34;&gt;&lt;code class=&#34;language-bash&#34;&gt;conda activate deepl &lt;span class=&#34;token comment&#34;&gt;# 激活对应环境&lt;/span&gt;
conda &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; libjepg-turbo
conda &lt;span class=&#34;token function&#34;&gt;install&lt;/span&gt; libpng&lt;span aria-hidden=&#34;true&#34; class=&#34;line-numbers-rows&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;若有其他缺少库报错，安装对应库即可，可以参考文章&lt;a href=&#34;https://0xdadream.github.io/2025/02/18/python-ku-bao-cuo-hui-zong/&#34;&gt;python库报错汇总 | 逐梦&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;总结&#34;&gt;&lt;a href=&#34;#总结&#34; class=&#34;headerlink&#34; title=&#34;总结&#34;&gt;&lt;/a&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;通过本教程，你已成功配置Intel显卡的AI开发环境，并验证了IPEX的GPU加速支持。接下来可尝试运行AI模型（如Stable Diffusion、LLM推理），并通过环境变量 &lt;code&gt;LIBOMPTARGET_PLUGIN=LEVEL0&lt;/code&gt; 或 &lt;code&gt;SYCL_CACHE_PERSISTENT=1&lt;/code&gt; 进一步优化性能。&lt;/p&gt;
&lt;h2 id=&#34;参考链接&#34;&gt;&lt;a href=&#34;#参考链接&#34; class=&#34;headerlink&#34; title=&#34;参考链接&#34;&gt;&lt;/a&gt;参考链接&lt;/h2&gt;&lt;p&gt;&lt;a href=&#34;https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html&#34;&gt;获取英特尔® oneAPI Base Toolkit&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://intel.github.io/intel-extension-for-pytorch/&#34;&gt;Welcome to Intel® Extension for PyTorch* Documentation!&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1dKaMeXE3B/?vd_source=b809bacd004cf290c08f612fa076f2eb&#34;&gt;intel arc 显卡 ComfyUI 安装教程_哔哩哔哩_bilibili&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://blog.csdn.net/yunying985/article/details/140589680&#34;&gt;AI绘画 | 只要10步让你在英特尔A770显卡下安装ComfyUI运行StableDiffusion3最新开源模型_arc a750 安装comfyui-CSDN博客&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://pytorch.org/docs/main/notes/get_start_xpu.html&#34;&gt;Getting Started on Intel GPU — PyTorch main documentation&lt;/a&gt;&lt;/p&gt;
 ]]></description>
        </item>
    </channel>
</rss>
