{
    "version": "https://jsonfeed.org/version/1",
    "title": "逐梦 • All posts by \"深度学习\" category",
    "description": "Welcome to my blog",
    "home_page_url": "https://0xdadream.github.io",
    "items": [
        {
            "id": "https://0xdadream.github.io/2025/02/18/arca770-shi-yong-comfyui-jiao-cheng/",
            "url": "https://0xdadream.github.io/2025/02/18/arca770-shi-yong-comfyui-jiao-cheng/",
            "title": "ArcA770使用comfyui教程",
            "date_published": "2025-02-18T10:11:00.000Z",
            "content_html": "<h1 id=\"ArcA770使用comfyui教程\"><a href=\"#ArcA770使用comfyui教程\" class=\"headerlink\" title=\"ArcA770使用comfyui教程\"></a>ArcA770使用comfyui教程</h1><h3 id=\"1-前置配置\"><a href=\"#1-前置配置\" class=\"headerlink\" title=\"1. 前置配置\"></a><strong>1. 前置配置</strong></h3><ul>\n<li>conda</li>\n<li>更新驱动</li>\n<li>安装<strong>Visual Studio Build Tools</strong></li>\n<li>安装oneAPI</li>\n<li>安装IPEX</li>\n<li>具体看链接<a href=\"https://0xdadream.github.io/2025/02/18/intel-xian-qia-pao-ai-pei-zhi-jiao-cheng/\">Intel显卡运行AI配置教程 | 逐梦</a></li>\n</ul>\n<hr>\n<h3 id=\"2-配置Python\"><a href=\"#2-配置Python\" class=\"headerlink\" title=\"2. 配置Python\"></a><strong>2. 配置Python</strong></h3><ul>\n<li><p><strong>Python环境</strong>：<br>建议使用<strong>Python 3.10或更高版本</strong>，并通过虚拟环境（如<code>venv</code>或<code>conda</code>）隔离依赖。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda create <span class=\"token parameter variable\">-n</span> comfyui <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.11</span>  这里comfyui就是安装IPEX的环境\nconda activate comfyui<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre></li>\n</ul>\n<hr>\n<h3 id=\"3-安装ComfyUI及依赖库\"><a href=\"#3-安装ComfyUI及依赖库\" class=\"headerlink\" title=\"3. 安装ComfyUI及依赖库\"></a><strong>3. 安装ComfyUI及依赖库</strong></h3><ul>\n<li><p><strong>克隆ComfyUI仓库</strong>：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> xxxx <span class=\"token comment\">#工作目录</span>\n<span class=\"token function\">git</span> clone https://github.com/comfyanonymous/ComfyUI.git\n<span class=\"token builtin class-name\">cd</span> ComfyUI\npip <span class=\"token function\">install</span> <span class=\"token parameter variable\">-r</span> requirements.txt <span class=\"token comment\"># 安装依赖</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre></li>\n</ul>\n<hr>\n<h3 id=\"4-验证显卡识别与性能调优\"><a href=\"#4-验证显卡识别与性能调优\" class=\"headerlink\" title=\"4. 验证显卡识别与性能调优\"></a><strong>4. 验证显卡识别与性能调优</strong></h3><ul>\n<li><strong>显存与算力优化</strong>：<ul>\n<li>启用Intel的<strong>XMX引擎</strong>（AI加速单元）和<strong>XeSS技术</strong>（超分辨率），可通过设置环境变量优化显存分配410。</li>\n<li>调整ComfyUI配置文件，指定使用<code>XPU</code>（Intel GPU）而非默认的CUDA。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"5-启动comfyui\"><a href=\"#5-启动comfyui\" class=\"headerlink\" title=\"5.启动comfyui\"></a><strong>5.启动comfyui</strong></h3><p>接着上面的目录执行</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">python main.py --use-pytorch-cross-attention <span class=\"token parameter variable\">--highvram</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<h4 id=\"快捷脚本\"><a href=\"#快捷脚本\" class=\"headerlink\" title=\"快捷脚本\"></a>快捷脚本</h4><h5 id=\"cmd\"><a href=\"#cmd\" class=\"headerlink\" title=\"cmd\"></a>cmd</h5><pre class=\"line-numbers language-bat\" data-language=\"bat\"><code class=\"language-bat\">call \"E:\\conda\\Scripts\\activate.bat\" deepl  \ncall \"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\"\npython main.py --use-pytorch-cross-attention --highvram<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n<p>保存为<code>.bat</code>文件</p>\n<p>powershell</p>\n<p>没搞出来</p>\n",
            "tags": [
                "intel"
            ]
        },
        {
            "id": "https://0xdadream.github.io/2025/02/18/intel-xian-qia-pao-ai-pei-zhi-jiao-cheng/",
            "url": "https://0xdadream.github.io/2025/02/18/intel-xian-qia-pao-ai-pei-zhi-jiao-cheng/",
            "title": "Intel显卡运行AI配置教程",
            "date_published": "2025-02-18T08:11:00.000Z",
            "content_html": "<h1 id=\"Intel显卡运行AI配置教程\"><a href=\"#Intel显卡运行AI配置教程\" class=\"headerlink\" title=\"Intel显卡运行AI配置教程\"></a><strong>Intel显卡运行AI配置教程</strong></h1><h2 id=\"最新\"><a href=\"#最新\" class=\"headerlink\" title=\"最新\"></a>最新</h2><p>最近pytorch已经支持Arc显卡了，不需要再安装oneAPI和IPEX，当然以前的版本仍需要（2.5及以前），但是我本地本来是安装过这些组件的，我也不知道不安装会不会报错，可以参考官方文档<a href=\"https://www.intel.com/content/www/us/en/developer/articles/tool/pytorch-prerequisites-for-intel-gpu/2-6.html\">PyTorch Prerequisites for Intel® GPUs</a>，pytorch开发者确实说过免去了那些复杂的操作，可以开箱即用</p>\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><p>直接在conda环境中执行即可</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda activate deepl\npip3 <span class=\"token function\">install</span> <span class=\"token parameter variable\">--pre</span> torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>输出true就是成功了</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\ntorch<span class=\"token punctuation\">.</span>xpu<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>  <span class=\"token comment\"># torch.xpu is the API for Intel GPU support</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>训练测试代码</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch\n<span class=\"token keyword\">import</span> torchvision\n\nLR <span class=\"token operator\">=</span> <span class=\"token number\">0.001</span>\nDOWNLOAD <span class=\"token operator\">=</span> <span class=\"token boolean\">True</span>\nDATA <span class=\"token operator\">=</span> <span class=\"token string\">\"datasets/cifar10/\"</span>\n\ntransform <span class=\"token operator\">=</span> torchvision<span class=\"token punctuation\">.</span>transforms<span class=\"token punctuation\">.</span>Compose<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">[</span>\n        torchvision<span class=\"token punctuation\">.</span>transforms<span class=\"token punctuation\">.</span>Resize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">224</span><span class=\"token punctuation\">,</span> <span class=\"token number\">224</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        torchvision<span class=\"token punctuation\">.</span>transforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        torchvision<span class=\"token punctuation\">.</span>transforms<span class=\"token punctuation\">.</span>Normalize<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span>\ntrain_dataset <span class=\"token operator\">=</span> torchvision<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>CIFAR10<span class=\"token punctuation\">(</span>\n    root<span class=\"token operator\">=</span>DATA<span class=\"token punctuation\">,</span>\n    train<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">,</span>\n    transform<span class=\"token operator\">=</span>transform<span class=\"token punctuation\">,</span>\n    download<span class=\"token operator\">=</span>DOWNLOAD<span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\ntrain_loader <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>utils<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>DataLoader<span class=\"token punctuation\">(</span>dataset<span class=\"token operator\">=</span>train_dataset<span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">)</span>\ntrain_len <span class=\"token operator\">=</span> <span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span>\n\nmodel <span class=\"token operator\">=</span> torchvision<span class=\"token punctuation\">.</span>models<span class=\"token punctuation\">.</span>resnet50<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\ncriterion <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>CrossEntropyLoss<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\noptimizer <span class=\"token operator\">=</span> torch<span class=\"token punctuation\">.</span>optim<span class=\"token punctuation\">.</span>SGD<span class=\"token punctuation\">(</span>model<span class=\"token punctuation\">.</span>parameters<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> lr<span class=\"token operator\">=</span>LR<span class=\"token punctuation\">,</span> momentum<span class=\"token operator\">=</span><span class=\"token number\">0.9</span><span class=\"token punctuation\">)</span>\nmodel<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nmodel <span class=\"token operator\">=</span> model<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"xpu\"</span><span class=\"token punctuation\">)</span>\ncriterion <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"xpu\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Initiating training\"</span></span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">for</span> batch_idx<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span> <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>train_loader<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    data <span class=\"token operator\">=</span> data<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"xpu\"</span><span class=\"token punctuation\">)</span>\n    target <span class=\"token operator\">=</span> target<span class=\"token punctuation\">.</span>to<span class=\"token punctuation\">(</span><span class=\"token string\">\"xpu\"</span><span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>zero_grad<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    output <span class=\"token operator\">=</span> model<span class=\"token punctuation\">(</span>data<span class=\"token punctuation\">)</span>\n    loss <span class=\"token operator\">=</span> criterion<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">,</span> target<span class=\"token punctuation\">)</span>\n    loss<span class=\"token punctuation\">.</span>backward<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    optimizer<span class=\"token punctuation\">.</span>step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> <span class=\"token punctuation\">(</span>batch_idx <span class=\"token operator\">+</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token operator\">%</span> <span class=\"token number\">10</span> <span class=\"token operator\">==</span> <span class=\"token number\">0</span><span class=\"token punctuation\">:</span>\n         iteration_loss <span class=\"token operator\">=</span> loss<span class=\"token punctuation\">.</span>item<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n         <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Iteration [</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>batch_idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">/</span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>train_len<span class=\"token punctuation\">}</span></span><span class=\"token string\">], Loss: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>iteration_loss<span class=\"token punctuation\">:</span><span class=\"token format-spec\">.4f</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>\ntorch<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">\"model_state_dict\"</span><span class=\"token punctuation\">:</span> model<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">\"optimizer_state_dict\"</span><span class=\"token punctuation\">:</span> optimizer<span class=\"token punctuation\">.</span>state_dict<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n    <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n    <span class=\"token string\">\"checkpoint.pth\"</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">\"Execution finished\"</span><span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p><strong>适用硬件</strong></p>\n<ul>\n<li>Intel Arc系列显卡（如A770 16G）驱动为6559</li>\n<li>win11</li>\n<li>oneAPI==2025.0.1</li>\n<li>torch==2.3.110</li>\n</ul>\n<hr>\n<h2 id=\"1-安装Miniconda并配置Python虚拟环境\"><a href=\"#1-安装Miniconda并配置Python虚拟环境\" class=\"headerlink\" title=\"1. 安装Miniconda并配置Python虚拟环境\"></a><strong>1. 安装Miniconda并配置Python虚拟环境</strong></h2><p>可以参考这个<a href=\"https://0xdadream.github.io/2024/08/12/conda-an-zhuang-ji-shi-yong/\">conda安装及使用 | 逐梦</a></p>\n<h3 id=\"步骤说明\"><a href=\"#步骤说明\" class=\"headerlink\" title=\"步骤说明\"></a><strong>步骤说明</strong></h3><ol>\n<li><p><strong>下载Miniconda</strong></p>\n<ul>\n<li>访问 <a href=\"https://docs.conda.io/en/latest/miniconda.html\">Miniconda官网</a>，选择对应操作系统的安装包（建议Python 3.11版本）。</li>\n</ul>\n</li>\n<li><p><strong>安装Miniconda</strong></p>\n<ul>\n<li><p>Windows：双击安装包，按提示操作，勾选“Add to PATH”选项。</p>\n</li>\n<li><p>Linux/macOS：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">bash</span> Miniconda3-latest-Linux-x86_64.sh  <span class=\"token comment\"># 根据文件名调整  </span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre></li>\n</ul>\n</li>\n<li><p><strong>创建Python 3.11虚拟环境</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda create <span class=\"token parameter variable\">-n</span> intel-ai <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.11</span>  \nconda activate intel-ai  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre></li>\n</ol>\n<hr>\n<h2 id=\"2-更新Intel显卡驱动\"><a href=\"#2-更新Intel显卡驱动\" class=\"headerlink\" title=\"2. 更新Intel显卡驱动\"></a><strong>2. 更新Intel显卡驱动</strong></h2><h3 id=\"关键操作\"><a href=\"#关键操作\" class=\"headerlink\" title=\"关键操作\"></a><strong>关键操作</strong></h3><ol>\n<li><p><strong>下载最新驱动</strong></p>\n<ul>\n<li>访问 <a href=\"https://www.intel.cn/content/www/cn/zh/download-center/home.html\">Intel驱动下载页</a>，选择Arc系列显卡的最新驱动（如<strong>32.0.101.6559</strong>）。</li>\n</ul>\n</li>\n<li><p><strong>安装驱动</strong></p>\n<ul>\n<li><p>Windows：运行安装程序，按提示完成安装。</p>\n</li>\n<li><p>Linux：使用包管理器（如Ubuntu/Debian）：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token function\">sudo</span> <span class=\"token function\">apt</span> <span class=\"token function\">install</span> intel-opencl-icd intel-level-zero-gpu level-zero  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre></li>\n</ul>\n</li>\n<li><p><strong>验证驱动状态</strong></p>\n<ul>\n<li><p>Windows：按 <code>Win + X</code> &gt; 设备管理器 &gt; 显示适配器，确认显卡型号正确。</p>\n</li>\n<li><p>Linux：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">lspci <span class=\"token operator\">|</span> <span class=\"token function\">grep</span> <span class=\"token parameter variable\">-i</span> intel  <span class=\"token comment\"># 确认显卡识别  </span>\nclinfo  <span class=\"token comment\"># 检查OpenCL支持  </span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre></li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"3-安装Visual-Studio-Build-Tools（仅Windows）\"><a href=\"#3-安装Visual-Studio-Build-Tools（仅Windows）\" class=\"headerlink\" title=\"3. 安装Visual Studio Build Tools（仅Windows）\"></a><strong>3. 安装Visual Studio Build Tools（仅Windows）</strong></h2><h3 id=\"操作步骤\"><a href=\"#操作步骤\" class=\"headerlink\" title=\"操作步骤\"></a><strong>操作步骤</strong></h3><ol>\n<li><strong>下载Visual Studio 2022</strong><ul>\n<li>访问 <a href=\"https://visualstudio.microsoft.com/\">Visual Studio官网</a>，下载社区版。</li>\n</ul>\n</li>\n<li><strong>安装C++桌面开发组件</strong><ul>\n<li>在安装界面勾选：<ul>\n<li><strong>使用C++的桌面开发</strong></li>\n<li><strong>Windows 10/11 SDK</strong></li>\n<li><strong>C++ CMake工具</strong></li>\n<li>默认也行</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>验证安装</strong><ul>\n<li>打开命令提示符，运行 <code>cl</code> 命令，确认返回编译器版本信息。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"4-安装Intel-oneAPI工具包\"><a href=\"#4-安装Intel-oneAPI工具包\" class=\"headerlink\" title=\"4. 安装Intel oneAPI工具包\"></a><strong>4. 安装Intel oneAPI工具包</strong></h2><h3 id=\"步骤说明-1\"><a href=\"#步骤说明-1\" class=\"headerlink\" title=\"步骤说明\"></a><strong>步骤说明</strong></h3><ol>\n<li><p><strong>下载oneAPI Base Toolkit</strong></p>\n<ul>\n<li>访问 <a href=\"https://www.intel.cn/content/www/cn/zh/developer/tools/oneapi/toolkits.html\">oneAPI官网</a>，选择Base Toolkit-&gt;windows-&gt;offline installer，然后点击右边往下一点Continue as a Guest (download starts immediately) →下载</li>\n</ul>\n</li>\n<li><p><strong>安装oneAPI</strong></p>\n<ul>\n<li>Windows：运行安装程序，默认勾选所有组件，一直点就行了。</li>\n<li>Linux：使用包管理器或脚本安装。</li>\n</ul>\n</li>\n<li><p><strong>激活oneAPI环境变量</strong></p>\n<ul>\n<li><p>Windows：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">call <span class=\"token string\">\"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\"</span>   <span class=\"token comment\"># cmd使用</span>\ncmd.exe <span class=\"token string\">\"/K\"</span> <span class=\"token string\">'\"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" &amp;&amp; powershell'</span> <span class=\"token comment\"># powershell使用</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li><p>Linux：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">source</span> /opt/intel/oneapi/setvars.sh  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre></li>\n</ul>\n</li>\n</ol>\n<hr>\n<h2 id=\"5-安装Intel-Extension-for-PyTorch-IPEX\"><a href=\"#5-安装Intel-Extension-for-PyTorch-IPEX\" class=\"headerlink\" title=\"5. 安装Intel Extension for PyTorch (IPEX)\"></a><strong>5. 安装Intel Extension for PyTorch (IPEX)</strong></h2><h3 id=\"操作命令\"><a href=\"#操作命令\" class=\"headerlink\" title=\"操作命令\"></a><strong>操作命令</strong></h3><ol>\n<li><p><strong>激活虚拟环境与oneAPI</strong></p>\n<p>powershell中执行</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token builtin class-name\">cd</span> xxx <span class=\"token comment\">#最好切换到工作目录</span>\nconda create <span class=\"token parameter variable\">-n</span> intel-ai <span class=\"token assign-left variable\">python</span><span class=\"token operator\">=</span><span class=\"token number\">3.11</span>  <span class=\"token comment\"># 前面创建过环境没有再次创建</span>\nconda activate intel-ai <span class=\"token comment\"># 激活环境 </span>\nconda <span class=\"token function\">install</span> libjepg-turbo <span class=\"token comment\">#提前安装这两个库以免报错</span>\nconda <span class=\"token function\">install</span> libpng \ncmd.exe <span class=\"token string\">\"/K\"</span> <span class=\"token string\">'\"C:\\Program Files (x86)\\Intel\\oneAPI\\setvars.bat\" &amp;&amp; powershell'</span>  <span class=\"token comment\"># 根据操作系统执行上述对应的oneAPI激活命令</span>\nconda activate intel-ai <span class=\"token comment\"># 再次激活环境</span>\nconda <span class=\"token function\">install</span> pkg-config libuv <span class=\"token comment\"># 安装一些依赖</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n</li>\n<li><p><strong>安装PyTorch与IPEX</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"><span class=\"token comment\"># 安装PyTorch CPU版本（IPEX会自动启用GPU支持）  </span>\npip <span class=\"token function\">install</span> <span class=\"token assign-left variable\">torch</span><span class=\"token operator\">==</span><span class=\"token number\">2.3</span>.1.post0+cxx11.abi <span class=\"token assign-left variable\">torchvision</span><span class=\"token operator\">==</span><span class=\"token number\">0.18</span>.1.post0+cxx11.abi <span class=\"token assign-left variable\">torchaudio</span><span class=\"token operator\">==</span><span class=\"token number\">2.3</span>.1.post0+cxx11.abi intel-extension-for-pytorch<span class=\"token operator\">==</span><span class=\"token number\">2.3</span>.110.post0+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/ <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">pip <span class=\"token function\">install</span> <span class=\"token assign-left variable\">torch</span><span class=\"token operator\">==</span><span class=\"token number\">2.5</span>.1+cxx11.abi <span class=\"token assign-left variable\">torchvision</span><span class=\"token operator\">==</span><span class=\"token number\">0.20</span>.1+cxx11.abi <span class=\"token assign-left variable\">torchaudio</span><span class=\"token operator\">==</span><span class=\"token number\">2.5</span>.1+cxx11.abi intel-extension-for-pytorch<span class=\"token operator\">==</span><span class=\"token number\">2.5</span>.10+xpu --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/cn/\n<span class=\"token comment\"># 最新版实测也能用</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre></li>\n</ol>\n<hr>\n<h2 id=\"6-验证IPEX安装与显卡识别\"><a href=\"#6-验证IPEX安装与显卡识别\" class=\"headerlink\" title=\"6. 验证IPEX安装与显卡识别\"></a><strong>6. 验证IPEX安装与显卡识别</strong></h2><h3 id=\"验证步骤\"><a href=\"#验证步骤\" class=\"headerlink\" title=\"验证步骤\"></a><strong>验证步骤</strong></h3><ol>\n<li><p><strong>运行Python脚本检查GPU支持</strong></p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> torch  \n<span class=\"token keyword\">import</span> intel_extension_for_pytorch <span class=\"token keyword\">as</span> ipex  \n\n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"PyTorch版本: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>torch<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"IPEX版本: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>ipex<span class=\"token punctuation\">.</span>__version__<span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"Intel GPU是否可用: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>torch<span class=\"token punctuation\">.</span>xpu<span class=\"token punctuation\">.</span>is_available<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>  \n<span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string-interpolation\"><span class=\"token string\">f\"检测到的Intel GPU设备: </span><span class=\"token interpolation\"><span class=\"token punctuation\">{</span>torch<span class=\"token punctuation\">.</span>xpu<span class=\"token punctuation\">.</span>get_device_name<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">}</span></span><span class=\"token string\">\"</span></span><span class=\"token punctuation\">)</span>  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">python <span class=\"token parameter variable\">-c</span> <span class=\"token string\">\"import torch; import intel_extension_for_pytorch as ipex; print('PyTorch版本:', torch.__version__); print('IPEX版本:', ipex.__version__); print('Intel GPU是否可用:', torch.xpu.is_available()); print('检测到的Intel GPU设备:', torch.xpu.get_device_name(0))\"</span>\n<span class=\"token comment\"># 一键脚本</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n</li>\n<li><p><strong>预期输出</strong></p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">PyTorch版本: <span class=\"token number\">2.1</span>.0  \nIPEX版本: <span class=\"token number\">2.1</span>.0  \nIntel GPU是否可用: True  \n检测到的Intel GPU设备: Intel<span class=\"token punctuation\">(</span>R<span class=\"token punctuation\">)</span> Arc<span class=\"token punctuation\">(</span>TM<span class=\"token punctuation\">)</span> A770 Graphics  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>官方脚本</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">python <span class=\"token parameter variable\">-c</span> <span class=\"token string\">\"import torch; import intel_extension_for_pytorch as ipex; print(torch.__version__); print(ipex.__version__); [print(f'[{i}]: {torch.xpu.get_device_properties(i)}') for i in range(torch.xpu.device_count())];\"</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>至此已经安装成功了</p>\n</li>\n</ol>\n<hr>\n<h2 id=\"7-常见问题解决\"><a href=\"#7-常见问题解决\" class=\"headerlink\" title=\"7. 常见问题解决\"></a><strong>7. 常见问题解决</strong></h2><p>遇到问题大多数时候都是各种版本不匹配，例如<code>raise err OSError: [WinError 126] 找不到指定的模块。</code>，尽量使用教程相同版本。</p>\n<p>报错信息</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">E:<span class=\"token punctuation\">\\</span>conda<span class=\"token punctuation\">\\</span>envs<span class=\"token punctuation\">\\</span>deepll<span class=\"token punctuation\">\\</span>Lib<span class=\"token punctuation\">\\</span>site-packages<span class=\"token punctuation\">\\</span>torchvision<span class=\"token punctuation\">\\</span>io<span class=\"token punctuation\">\\</span>image.py:14: UserWarning: Failed to load image Python extension: <span class=\"token string\">'Could not find module '</span>E:<span class=\"token punctuation\">\\</span>conda<span class=\"token punctuation\">\\</span>envs<span class=\"token punctuation\">\\</span>deepll<span class=\"token punctuation\">\\</span>Lib<span class=\"token punctuation\">\\</span>site-packages<span class=\"token punctuation\">\\</span>torchvision<span class=\"token punctuation\">\\</span>image.pyd<span class=\"token string\">' (or one of its dependencies). Try using the full path with constructor syntax.'</span>If you don't plan on using image functionality from <span class=\"token variable\"><span class=\"token variable\">`</span>torchvision.io<span class=\"token variable\">`</span></span>, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have <span class=\"token variable\"><span class=\"token variable\">`</span>libjpeg<span class=\"token variable\">`</span></span> or <span class=\"token variable\"><span class=\"token variable\">`</span>libpng<span class=\"token variable\">`</span></span> installed before building <span class=\"token variable\"><span class=\"token variable\">`</span>torchvision<span class=\"token variable\">`</span></span> from source?\n  warn<span class=\"token punctuation\">(</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>解决方案</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">conda activate deepl <span class=\"token comment\"># 激活对应环境</span>\nconda <span class=\"token function\">install</span> libjepg-turbo\nconda <span class=\"token function\">install</span> libpng<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span></span></code></pre>\n\n<p>若有其他缺少库报错，安装对应库即可，可以参考文章<a href=\"https://0xdadream.github.io/2025/02/18/python-ku-bao-cuo-hui-zong/\">python库报错汇总 | 逐梦</a></p>\n<hr>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h2><p>通过本教程，你已成功配置Intel显卡的AI开发环境，并验证了IPEX的GPU加速支持。接下来可尝试运行AI模型（如Stable Diffusion、LLM推理），并通过环境变量 <code>LIBOMPTARGET_PLUGIN=LEVEL0</code> 或 <code>SYCL_CACHE_PERSISTENT=1</code> 进一步优化性能。</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><a href=\"https://www.intel.com/content/www/us/en/developer/tools/oneapi/base-toolkit-download.html\">获取英特尔® oneAPI Base Toolkit</a></p>\n<p><a href=\"https://intel.github.io/intel-extension-for-pytorch/\">Welcome to Intel® Extension for PyTorch* Documentation!</a></p>\n<p><a href=\"https://www.bilibili.com/video/BV1dKaMeXE3B/?vd_source=b809bacd004cf290c08f612fa076f2eb\">intel arc 显卡 ComfyUI 安装教程_哔哩哔哩_bilibili</a></p>\n<p><a href=\"https://blog.csdn.net/yunying985/article/details/140589680\">AI绘画 | 只要10步让你在英特尔A770显卡下安装ComfyUI运行StableDiffusion3最新开源模型_arc a750 安装comfyui-CSDN博客</a></p>\n<p><a href=\"https://pytorch.org/docs/main/notes/get_start_xpu.html\">Getting Started on Intel GPU — PyTorch main documentation</a></p>\n",
            "tags": [
                "intel"
            ]
        }
    ]
}